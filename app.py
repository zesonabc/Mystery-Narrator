import streamlit as st
import requests
import pandas as pd
import json
import re
import time
import zipfile
import io
import uuid
import os

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="MysteryNarrator V26 (å·¥ç¨‹ä¿®å¤ç‰ˆ)", page_icon="ğŸ› ï¸", layout="wide")
st.markdown("""
<style>
    .stApp { background-color: #121212; color: #e0e0e0; }
    .stButton > button { background-color: #FF5252; color: white; border: none; padding: 12px; font-weight: bold; border-radius: 6px; }
    .stSuccess { background-color: #2e7d32; color: white; }
    img:hover { transform: scale(1.02); transition: 0.3s; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. å‰ªæ˜ è‰ç¨¿ç”Ÿæˆå™¨ (ç»“æ„æ·±åº¦ä¼˜åŒ–)
# ==========================================
class JianyingDraftGenerator:
    def __init__(self):
        self.materials = {"videos": [], "audios": [], "texts": [], "canvas_animations": [], "speeds": [], "sound_channel_mappings": []}
        self.tracks = []
        self.width = 1920
        self.height = 1080
        self.us_base = 1000000 

    def _get_id(self): return str(uuid.uuid4()).upper()

    def add_media_track(self, shot_df, audio_duration_us):
        # 1. è§†é¢‘è½¨é“ (Images)
        video_segments = []
        current_offset = 0
        for i, row in shot_df.iterrows():
            material_id = self._get_id()
            # å¼ºåˆ¶æ•´æ•°æ—¶é•¿
            duration_us = int(round(row['duration'] * self.us_base))
            
            self.materials["videos"].append({
                "id": material_id, 
                "type": "photo", 
                "path": f"D:/Mystery_Project/media/{i+1:03d}.jpg", # è™šæ‹Ÿè·¯å¾„
                "duration": 10800000000, # å›¾ç‰‡ç´ æé»˜è®¤é•¿åº¦ç»™å¤§ä¸€ç‚¹
                "width": self.width, 
                "height": self.height, 
                "name": f"{i+1:03d}.jpg"
            })
            
            video_segments.append({
                "id": self._get_id(), 
                "material_id": material_id,
                "target_timerange": {"duration": duration_us, "start": current_offset},
                "source_timerange": {"duration": duration_us, "start": 0}
            })
            current_offset += duration_us
            
        self.tracks.append({"id": self._get_id(), "type": "video", "segments": video_segments})

        # 2. å­—å¹•è½¨é“ (Texts)
        text_segments = []
        current_offset = 0
        for i, row in shot_df.iterrows():
            duration_us = int(round(row['duration'] * self.us_base))
            text_id = self._get_id()
            
            # æ ·å¼ï¼šç™½å­—é»‘è¾¹
            content = {
                "text": str(row['script']), 
                "styles": [{"fill": {"color": [1.0, 1.0, 1.0]}}], 
                "strokes": [{"color": [0.0, 0.0, 0.0], "width": 0.05}]
            }
            
            self.materials["texts"].append({
                "id": text_id, 
                "type": "text", 
                "content": json.dumps(content), 
                "font_size": 12.0
            })
            
            text_segments.append({
                "id": self._get_id(), 
                "material_id": text_id,
                "target_timerange": {"duration": duration_us, "start": current_offset},
                "source_timerange": {"duration": duration_us, "start": 0}
            })
            current_offset += duration_us
            
        self.tracks.append({"id": self._get_id(), "type": "text", "segments": text_segments})

    def add_audio_track(self, audio_filename, duration_us):
        audio_id = self._get_id()
        self.materials["audios"].append({
            "id": audio_id, 
            "path": f"D:/Mystery_Project/media/{audio_filename}", 
            "duration": duration_us, 
            "type": "extract_music", 
            "name": audio_filename
        })
        
        self.tracks.append({"id": self._get_id(), "type": "audio", "segments": [{
            "id": self._get_id(), 
            "material_id": audio_id, 
            "target_timerange": {"duration": duration_us, "start": 0}, 
            "source_timerange": {"duration": duration_us, "start": 0}
        }]})

    def generate_json(self):
        # å¢åŠ ä¸€äº›ç©ºåˆ—è¡¨ä»¥åŒ¹é…æ ‡å‡†æ ¼å¼ï¼Œé˜²æ­¢åŠ è½½å¡æ­»
        return {
            "id": self._get_id(), 
            "materials": self.materials, 
            "tracks": self.tracks, 
            "version": 2, 
            "config": {"width": self.width, "height": self.height},
            "platform": {"os": "windows"}
        }

# ==========================================
# 3. æ ¸å¿ƒ API (ä¿®å¤ KeyError)
# ==========================================
def get_headers(api_key): return {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
def clean_json_text(text): return re.sub(r'<think>.*?</think>', '', re.sub(r'```json|```', '', text), flags=re.DOTALL).strip()

def transcribe_audio(audio_file, api_key):
    url = "https://api.siliconflow.cn/v1/audio/transcriptions"
    audio_file.seek(0)
    files = {'file': (audio_file.name, audio_file.getvalue(), audio_file.type), 'model': (None, 'FunAudioLLM/SenseVoiceSmall'), 'response_format': (None, 'verbose_json')}
    try: return requests.post(url, headers={"Authorization": f"Bearer {api_key}"}, files=files, timeout=60).json()
    except: return None

def extract_characters_silicon(script, model, key):
    url = "https://api.siliconflow.cn/v1/chat/completions"
    sys_prompt = "æå–ä¸­å›½æ‚¬ç–‘å‰§æœ¬è§’è‰²ã€‚è§„åˆ™ï¼š1. é»˜è®¤ä¸­å›½é¢å­”(Asian Chinese)ã€‚2. è¾“å‡ºJSON List: [{'name':'xx','prompt':'...'}]"
    try:
        res = requests.post(url, json={"model":model,"messages":[{"role":"system","content":sys_prompt},{"role":"user","content":script}],"response_format":{"type":"json_object"}}, headers=get_headers(key), timeout=45)
        df = pd.DataFrame(json.loads(clean_json_text(res.json()['choices'][0]['message']['content'])))
        if not df.empty: df = df[~df['name'].str.contains('åšä¸»|æˆ‘|Host',case=False,na=False)]
        return df
    except: return pd.DataFrame(columns=['name', 'prompt']) # è¿”å›å¸¦åˆ—åçš„ç©ºè¡¨

def analyze_segments_robust(segments, script_text, char_names, style, res_p, model, key):
    final_segments = []
    
    # 1. æ•°æ®æºå‡†å¤‡
    if segments:
        final_segments = segments
    elif script_text and len(script_text.strip()) > 0:
        # Bè®¡åˆ’ï¼šæ–‡æ¡ˆä¸ä¸ºç©ºï¼Œè¿›è¡Œåˆ‡åˆ†
        chunks = re.split(r'([ã€‚ï¼Ÿï¼ï¼›\n])', script_text)
        current = ""
        for chunk in chunks:
            if len(current) + len(chunk) < 18 and not re.match(r'[ã€‚ï¼Ÿï¼\n]', chunk): current += chunk
            else: 
                if current: 
                    dur = max(2.0, len(current) * 0.22)
                    final_segments.append({"text": current, "duration": dur})
                current = chunk
        if current: 
            dur = max(2.0, len(current) * 0.22)
            final_segments.append({"text": current, "duration": dur})
    
    # ã€ä¿®å¤æ ¸å¿ƒã€‘å¦‚æœåˆ°è¿™é‡Œ final_segments è¿˜æ˜¯ç©ºçš„ï¼Œç›´æ¥è¿”å›ä¸€ä¸ªæ ‡å‡†çš„ç©º DataFrame
    # å¿…é¡»åŒ…å«æ‰€æœ‰åç»­æ­¥éª¤éœ€è¦çš„åˆ—åï¼
    if not final_segments:
        return pd.DataFrame(columns=['duration', 'script', 'type', 'final_prompt'])

    try:
        # 2. AI åˆ†æ
        char_list = ", ".join(char_names) if char_names else "æ— ç‰¹å®šè§’è‰²"
        sys_prompt = f"""
        ä½ æ˜¯ä¸­å›½æ‚¬ç–‘å¯¼æ¼”ã€‚è§’è‰²:{char_list}ã€‚é£æ ¼:{style}ã€‚æ„å›¾:{res_p}ã€‚
        ä»»åŠ¡: ä¸ºæ¯ä¸€å¥å­—å¹•è®¾è®¡ç”»é¢ Promptã€‚
        è§„åˆ™:
        1. å¼ºåˆ¶ä¸­å›½èƒŒæ™¯(Chinese setting)ï¼Œä¸­å›½äºº(Asian Chinese face)ã€‚
        2. é‡åˆ°è§’è‰²å†™å ä½ç¬¦[Name]ã€‚
        è¾“å‡º JSON: {{"segments": [...]}}
        """
        
        input_json = json.dumps([{"id":i,"text":s.get('text','')} for i,s in enumerate(final_segments)], ensure_ascii=False)
        res = requests.post("https://api.siliconflow.cn/v1/chat/completions", json={"model":model,"messages":[{"role":"system","content":sys_prompt},{"role":"user","content":input_json}],"response_format":{"type":"json_object"}}, headers=get_headers(key), timeout=90)
        
        result_list = json.loads(clean_json_text(res.json()['choices'][0]['message']['content'])).get('segments', [])
        
        merged = []
        for i, seg in enumerate(final_segments):
            vis = next((item for item in result_list if item.get('index') == i), None)
            dur = seg.get('duration')
            if dur is None: dur = seg['end'] - seg['start']
            
            merged.append({
                "duration": dur,
                "script": seg.get('text'),
                "type": vis['type'] if vis else "SCENE",
                "final_prompt": vis['final_prompt'] if vis else f"Chinese suspense scene, {style}"
            })
        return pd.DataFrame(merged)

    except:
        # å…œåº•
        fallback = []
        for seg in final_segments:
            dur = seg.get('duration')
            if dur is None: dur = max(2.0, len(seg.get('text','')) * 0.22)
            fallback.append({"duration": dur, "script": seg.get('text'), "type": "SCENE", "final_prompt": f"Chinese suspense shot, {style}"})
        return pd.DataFrame(fallback)

# ã€ä¿®å¤æ ¸å¿ƒã€‘é˜²æ­¢ KeyError
def inject_character_prompts(shot_df, char_df):
    # æ£€æŸ¥ DataFrame æ˜¯å¦ä¸ºç©ºï¼Œæˆ–è€…æ˜¯å¦ç¼ºå°‘åˆ—
    if shot_df is None or shot_df.empty or 'final_prompt' not in shot_df.columns:
        # å¦‚æœæœ‰é—®é¢˜ï¼Œè¿”å›ä¸€ä¸ªå®‰å…¨çš„ç©ºè¡¨
        return pd.DataFrame(columns=['duration', 'script', 'type', 'final_prompt'])
    
    char_dict = {f"[{row['name']}]": row['prompt'] for _, row in char_df.iterrows()}
    
    def replace(p):
        for ph in re.findall(r'\[.*?\]', str(p)):
            if ph in char_dict: p = p.replace(ph, f"({char_dict[ph]}, Chinese face:1.4)")
        if "Chinese" not in str(p): p = f"(Chinese environment:1.3), {p}"
        return p
        
    shot_df['final_prompt'] = shot_df['final_prompt'].apply(replace)
    return shot_df

def generate_image(prompt, size, key):
    try:
        width, height = 1280, 720 if "16:9" in size else 720, 1280
        res = requests.post("https://api.siliconflow.cn/v1/images/generations", json={"model":"black-forest-labs/FLUX.1-schnell","prompt":prompt,"image_size":f"{width}x{height}","batch_size":1,"num_inference_steps":4,"guidance_scale":3.5}, headers=get_headers(key), timeout=50)
        return res.json()['images'][0]['url'] if res.status_code == 200 else "Error"
    except: return "Error"

# ã€ä¿®å¤æ ¸å¿ƒã€‘ZIP ç»“æ„ä¼˜åŒ–ï¼šå¤–å±‚åŒ…è£¹ä¸€ä¸ªæ–‡ä»¶å¤¹
def create_draft_zip(shot_df, imgs, audio_bytes, audio_name):
    buf = io.BytesIO()
    generator = JianyingDraftGenerator()
    total_duration_us = int(shot_df['duration'].sum() * 1000000)
    generator.add_audio_track(audio_name, total_duration_us)
    generator.add_media_track(shot_df, total_duration_us)
    
    draft_content = generator.generate_json()
    draft_meta = {"id": draft_content["id"], "name": "Mystery_Project", "last_modified": int(time.time()*1000)}
    
    # ç®€å•çš„å ä½æ–‡ä»¶ï¼Œè®©å‰ªæ˜ è§‰å¾—è¿™æ˜¯ä¸ªæ­£ç»è‰ç¨¿
    virtual_store = {"virtual_objects": []}

    # å®šä¹‰æ ¹ç›®å½•å
    root_dir = "Mystery_Project_Draft"

    with zipfile.ZipFile(buf, "w") as zf:
        # æŠŠæ–‡ä»¶éƒ½å†™åœ¨ Mystery_Project_Draft/ ç›®å½•ä¸‹
        zf.writestr(f"{root_dir}/draft_content.json", json.dumps(draft_content, indent=4))
        zf.writestr(f"{root_dir}/draft_meta_info.json", json.dumps(draft_meta, indent=4))
        zf.writestr(f"{root_dir}/draft_virtual_store.json", json.dumps(virtual_store, indent=4))
        
        zf.writestr(f"{root_dir}/media/{audio_name}", audio_bytes)
        for i, u in imgs.items():
            try: zf.writestr(f"{root_dir}/media/{i+1:03d}.jpg", requests.get(u).content)
            except: pass
    return buf

# ==========================================
# 4. ç•Œé¢
# ==========================================
if 'char_df' not in st.session_state: st.session_state.char_df = None
if 'shot_df' not in st.session_state: st.session_state.shot_df = None
if 'gen_imgs' not in st.session_state: st.session_state.gen_imgs = {}
if 'audio_data' not in st.session_state: st.session_state.audio_data = None
if 'segments' not in st.session_state: st.session_state.segments = []

with st.sidebar:
    st.markdown("### ğŸ”‘ Key"); api_key = st.text_input("SiliconFlow Key", type="password")
    st.markdown("### ğŸ•µï¸ åšä¸»"); fixed_host = st.text_area("Prompt", "(A 30-year-old Chinese man, Asian face, black hair, green cap, leather jacket:1.4), looking at camera", height=80)
    st.markdown("### ğŸ§  è®¾ç½®"); model = st.selectbox("å¤§è„‘", ["deepseek-ai/DeepSeek-V3", "Qwen/Qwen2.5-72B-Instruct"])
    aspect = st.selectbox("ç”»å¹…", ["16:9 (æ¨ªå±)", "9:16 (ç«–å±)"])
    style = st.text_area("é£æ ¼", "Film noir, suspense thriller, Chinese background.", height=60)
    st.info("ğŸ¨ ç»˜å›¾: FLUX.1-schnell")

st.title("ğŸ› ï¸ MysteryNarrator V26 (å·¥ç¨‹ä¿®å¤ç‰ˆ)")
st.caption("ä¿®å¤ KeyError | ä¼˜åŒ–è‰ç¨¿ç»“æ„ | å›½é£ä¿®æ­£")

c1, c2 = st.columns(2)
with c1: script_input = st.text_area("1. ç²˜è´´æ–‡æ¡ˆ (å¦‚æœå½•éŸ³å¬å†™å¤±è´¥ï¼Œå°†ä½¿ç”¨æ­¤æ–‡æ¡ˆ)", height=150)
with c2: audio = st.file_uploader("2. ä¸Šä¼ å½•éŸ³", type=['mp3','wav','m4a'])

if st.button("ğŸ” 3. æ™ºèƒ½åˆ†æ"):
    if not api_key: st.error("è¯·å¡« Key")
    # æ”¾å®½é™åˆ¶ï¼šåªè¦æœ‰å…¶ä¸­ä¸€æ ·å°±è¡Œï¼Œä¼˜å…ˆå½•éŸ³
    elif not script_input and not audio: st.error("æ–‡æ¡ˆæˆ–å½•éŸ³è‡³å°‘è¦æœ‰ä¸€ä¸ª")
    else:
        # å¤„ç†éŸ³é¢‘
        if audio:
            st.session_state.audio_data = {"name": audio.name, "bytes": audio.getvalue()}
            with st.spinner("å¬å†™ä¸­..."):
                asr = transcribe_audio(audio, api_key)
                if asr and 'segments' in asr:
                    st.session_state.segments = asr['segments']
                    st.success("âœ… å½•éŸ³å¯¹é½æˆåŠŸ")
                else:
                    st.session_state.segments = []
                    st.warning("âš ï¸ å¬å†™å¤±è´¥ï¼Œå°†ä½¿ç”¨æ–‡æ¡ˆä¼°ç®—")
        else:
            # æ²¡ä¼ éŸ³é¢‘ï¼Œé€ ä¸€ä¸ªå‡çš„éŸ³é¢‘æ•°æ®é˜²æ­¢æŠ¥é”™
            st.session_state.audio_data = {"name": "silent.mp3", "bytes": b""}
            st.session_state.segments = []

        # å¤„ç†è§’è‰²
        if script_input:
            df = extract_characters_silicon(script_input, model, api_key)
            host = pd.DataFrame([{"name":"åšä¸»(æˆ‘)", "prompt":fixed_host}])
            st.session_state.char_df = pd.concat([host, df], ignore_index=True)
        else:
            # æ²¡æ–‡æ¡ˆå°±åªç•™åšä¸»
            st.session_state.char_df = pd.DataFrame([{"name":"åšä¸»(æˆ‘)", "prompt":fixed_host}])
            st.warning("âš ï¸ æ²¡æä¾›æ–‡æ¡ˆï¼Œåªèƒ½ç”Ÿæˆåšä¸»ç”»é¢")

if st.session_state.char_df is not None:
    st.session_state.char_df = st.data_editor(st.session_state.char_df, num_rows="dynamic", key="c_ed", use_container_width=True)
    if st.button("ğŸ¬ 4. ç”Ÿæˆåˆ†é•œ"):
        with st.spinner("å¯¼æ¼”è®¾è®¡ä¸­..."):
            c_list = st.session_state.char_df['name'].tolist()
            # ç¡®ä¿ script_input ä¸ä¸º None
            safe_script = script_input if script_input else ""
            df = analyze_segments_robust(st.session_state.segments, safe_script, c_list, style, aspect, model, api_key)
            
            # ã€å…³é”®ã€‘è¿™é‡Œä¸ä¼šå†æŠ¥ KeyError äº†
            st.session_state.shot_df = inject_character_prompts(df, st.session_state.char_df)
            
            if st.session_state.shot_df.empty:
                st.error("âŒ ç”Ÿæˆçš„åˆ†é•œè¡¨ä¸ºç©ºï¼è¯·æ£€æŸ¥æ˜¯å¦è¾“å…¥äº†æœ‰æ•ˆçš„æ–‡æ¡ˆã€‚")
            else:
                st.success("OK")

if st.session_state.shot_df is not None and not st.session_state.shot_df.empty:
    st.session_state.shot_df = st.data_editor(st.session_state.shot_df, num_rows="dynamic", key="s_ed", use_container_width=True)
    c1, c2 = st.columns(2)
    if c1.button("ğŸ¨ 5. FLUX ç»˜å›¾"):
        bar = st.progress(0); tot = len(st.session_state.shot_df); prev = st.columns(4)
        for i, r in st.session_state.shot_df.iterrows():
            url = generate_image(r['final_prompt'], aspect, api_key)
            if "Error" not in url:
                st.session_state.gen_imgs[i] = url
                with prev[i%4]: st.image(url, caption=f"#{i+1}", use_column_width=True)
            bar.progress((i+1)/tot); time.sleep(2)
        st.success("å®Œæˆ!")
    if c2.button("ğŸ“¦ 6. ä¸‹è½½è‰ç¨¿åŒ…"):
        if st.session_state.gen_imgs:
            zip_buf = create_draft_zip(st.session_state.shot_df, st.session_state.gen_imgs, st.session_state.audio_data["bytes"], st.session_state.audio_data["name"])
            st.download_button("â¬‡ï¸ ä¸‹è½½è‰ç¨¿åŒ…", zip_buf.getvalue(), "Jianying_Mystery_Draft.zip", "application/zip", type="primary")
        else: st.warning("å…ˆç»˜å›¾")
