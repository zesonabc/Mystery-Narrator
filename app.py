import streamlit as st
import requests
import pandas as pd
import json
import re
import time
import zipfile
import io
import uuid
import os

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="MysteryNarrator V17 (å®Œç¾è‰ç¨¿ç‰ˆ)", page_icon="ğŸ“¦", layout="wide")
st.markdown("""
<style>
    .stApp { background-color: #121212; color: #e0e0e0; }
    .stButton > button { background-color: #00C853; color: white; border: none; padding: 12px; font-weight: bold; border-radius: 6px; }
    .stButton > button:hover { background-color: #009624; }
    .stSuccess { background-color: #2e7d32; color: white; }
    .stInfo { background-color: #0277bd; color: white; }
    img { border-radius: 5px; border: 1px solid #333; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. å‰ªæ˜ è‰ç¨¿ç”Ÿæˆå™¨ (JianyingPro Draft)
# ==========================================
class JianyingDraftGenerator:
    def __init__(self):
        self.materials = {"videos": [], "audios": [], "texts": [], "canvas_animations": []}
        self.tracks = []
        self.width = 1920
        self.height = 1080
        self.us_base = 1000000 

    def _get_id(self): return str(uuid.uuid4()).upper()

    def add_media_track(self, shot_df, audio_duration_us):
        # --- è§†é¢‘è½¨é“ (å›¾ç‰‡) ---
        video_segments = []
        current_offset = 0
        
        for i, row in shot_df.iterrows():
            material_id = self._get_id()
            # é‡æ–°è®¡ç®— duration (é¿å…æµ®ç‚¹è¯¯å·®)
            duration_us = int(row['duration'] * self.us_base)
            
            self.materials["videos"].append({
                "id": material_id,
                "type": "photo",
                "path": f"D:/Mystery_Project/media/{i+1:03d}.jpg", # è™šæ‹Ÿè·¯å¾„ï¼Œå¯¼å…¥æ—¶é‡è¿
                "duration": 10800000000, 
                "width": self.width,
                "height": self.height,
                "name": f"{i+1:03d}.jpg"
            })
            
            video_segments.append({
                "id": self._get_id(),
                "material_id": material_id,
                "target_timerange": {"duration": duration_us, "start": current_offset},
                "source_timerange": {"duration": duration_us, "start": 0}
            })
            current_offset += duration_us
            
        self.tracks.append({"id": self._get_id(), "type": "video", "segments": video_segments})

        # --- å­—å¹•è½¨é“ (Text) ---
        text_segments = []
        current_offset = 0
        for i, row in shot_df.iterrows():
            duration_us = int(row['duration'] * self.us_base)
            text_id = self._get_id()
            
            # å­—å¹•æ ·å¼ï¼šç™½è‰²å­—ï¼Œé»‘è‰²æè¾¹ (é˜²èƒŒæ™¯å¹²æ‰°)
            content_obj = {
                "text": row['script'], 
                "styles": [{"fill": {"color": [1.0, 1.0, 1.0]}}],
                "strokes": [{"color": [0.0, 0.0, 0.0], "width": 0.05}] 
            }
            
            self.materials["texts"].append({
                "id": text_id,
                "type": "text",
                "content": json.dumps(content_obj),
                "font_size": 12.0 # å­—ä½“å¤§å°
            })
            
            text_segments.append({
                "id": self._get_id(),
                "material_id": text_id,
                "target_timerange": {"duration": duration_us, "start": current_offset},
                "source_timerange": {"duration": duration_us, "start": 0}
            })
            current_offset += duration_us

        self.tracks.append({"id": self._get_id(), "type": "text", "segments": text_segments})

    def add_audio_track(self, audio_filename, duration_us):
        audio_id = self._get_id()
        self.materials["audios"].append({
            "id": audio_id,
            "path": f"D:/Mystery_Project/media/{audio_filename}", # è™šæ‹Ÿè·¯å¾„
            "duration": duration_us,
            "type": "extract_music",
            "name": audio_filename
        })
        
        self.tracks.append({"id": self._get_id(), "type": "audio", "segments": [{
            "id": self._get_id(),
            "material_id": audio_id,
            "target_timerange": {"duration": duration_us, "start": 0},
            "source_timerange": {"duration": duration_us, "start": 0}
        }]})

    def generate_json(self):
        return {
            "id": self._get_id(),
            "materials": self.materials,
            "tracks": self.tracks,
            "version": 3,
            "config": {"width": self.width, "height": self.height}
        }

# ==========================================
# 3. æ ¸å¿ƒ API å‡½æ•°
# ==========================================
def get_headers(api_key): return {"Authorization": f"Bearer {api_key}"}
def clean_json_text(text): return re.sub(r'<think>.*?</think>', '', re.sub(r'```json|```', '', text), flags=re.DOTALL).strip()

# å¬å†™ (è·å–æ—¶é—´è½´)
def transcribe_audio(audio_file, api_key):
    url = "https://api.siliconflow.cn/v1/audio/transcriptions"
    files = {'file': (audio_file.name, audio_file.getvalue(), audio_file.type), 'model': (None, 'FunAudioLLM/SenseVoiceSmall'), 'response_format': (None, 'verbose_json')}
    try: return requests.post(url, headers=get_headers(api_key), files=files, timeout=60).json()
    except: return None

# è§’è‰²åˆ†æ (ä¼˜å…ˆç”¨æ–‡æ¡ˆåˆ†æï¼Œæ›´å‡†)
def extract_characters_silicon(script, model, key):
    url = "https://api.siliconflow.cn/v1/chat/completions"
    sys_prompt = "æå–æ–‡æ¡ˆä¸­çš„ã€å‰§æƒ…è§’è‰²ã€‘ã€‚è¾“å‡ºJSONåˆ—è¡¨: [{'name':'xx','prompt':'...'}]"
    try:
        res = requests.post(url, json={"model": model, "messages": [{"role":"system","content":sys_prompt}, {"role":"user","content":script}], "response_format": {"type": "json_object"}}, headers={"Authorization": f"Bearer {key}", "Content-Type": "application/json"}, timeout=30)
        df = pd.DataFrame(json.loads(clean_json_text(res.json()['choices'][0]['message']['content'])))
        if not df.empty: df = df[~df['name'].str.contains('åšä¸»|æˆ‘|Host', case=False, na=False)]
        return df
    except: return None

# åˆ†é•œè®¾è®¡ (ä½¿ç”¨éŸ³é¢‘çš„æ—¶é—´è½´ï¼Œæ–‡æ¡ˆçš„å†…å®¹)
def analyze_segments(segments, char_names, style, res_p, model, key):
    input_data = json.dumps([{"id":i,"text":s['text']} for i,s in enumerate(segments)], ensure_ascii=False)
    char_list = ", ".join(char_names)
    sys_prompt = f"""
    æ‚¬ç–‘å¯¼æ¼”ã€‚è§’è‰²:{char_list}ã€‚é£æ ¼:{style}ã€‚æ„å›¾:{res_p}ã€‚
    ä»»åŠ¡: ä¸ºæ¯ä¸€å¥å­—å¹•è®¾è®¡ç”»é¢ã€‚Prompt: é‡è§’è‰²å†™å ä½ç¬¦[Name]ã€‚
    è¾“å‡ºJSONåˆ—è¡¨ "index", "type", "final_prompt"
    """
    try:
        res = requests.post("https://api.siliconflow.cn/v1/chat/completions", json={"model":model,"messages":[{"role":"system","content":sys_prompt},{"role":"user","content":input_data}],"response_format":{"type":"json_object"}}, headers={"Authorization":f"Bearer {key}","Content-Type":"application/json"}, timeout=60)
        result_list = json.loads(clean_json_text(res.json()['choices'][0]['message']['content']))
        if isinstance(result_list, dict): result_list = result_list.get('segments', [])
        
        merged = []
        for i, seg in enumerate(segments):
            vis = next((item for item in result_list if item.get('index') == i), None)
            duration = seg['end'] - seg['start']
            merged.append({
                "duration": duration, 
                "script": seg['text'], 
                "type": vis['type'] if vis else "SCENE", 
                "final_prompt": vis['final_prompt'] if vis else f"Suspense scene, {style}"
            })
        return pd.DataFrame(merged)
    except: return None

# è§’è‰²æ³¨å…¥ (é”è„¸)
def inject_character_prompts(shot_df, char_df):
    if shot_df is None or char_df is None: return shot_df
    char_dict = {f"[{row['name']}]": row['prompt'] for _, row in char_df.iterrows()}
    def replace(p):
        for ph in re.findall(r'\[.*?\]', p):
            if ph in char_dict: p = p.replace(ph, f"({char_dict[ph]}:1.4)")
        return p
    shot_df['final_prompt'] = shot_df['final_prompt'].apply(replace)
    return shot_df

# ç”»å›¾
def generate_image(prompt, size, key):
    try:
        res = requests.post("https://api.siliconflow.cn/v1/images/generations", json={"model":"Kwai-Kolors/Kolors","prompt":prompt,"image_size":size,"batch_size":1}, headers={"Authorization":f"Bearer {key}","Content-Type":"application/json"}, timeout=30)
        return res.json()['data'][0]['url'] if res.status_code == 200 else "Error"
    except: return "Error"

# å¼ºåˆ¶åˆ‡åˆ† (å¤„ç†é•¿éš¾å¥)
def split_long_segments(raw_segments, max_len=18):
    new_segments = []
    for seg in raw_segments:
        text = seg['text']; start = seg['start']; end = seg['end']; duration = end - start
        if len(text) > max_len:
            parts = [text[i:i+max_len] for i in range(0, len(text), max_len)]
            part_dur = duration / len(parts)
            for i, part in enumerate(parts):
                new_segments.append({"text": part, "start": start+(i*part_dur), "end": start+((i+1)*part_dur)})
        else: new_segments.append(seg)
    return new_segments

# ==========================================
# 4. æ‰“åŒ…åŠŸèƒ½
# ==========================================
def create_draft_zip(shot_df, imgs, audio_bytes, audio_name):
    buf = io.BytesIO()
    generator = JianyingDraftGenerator()
    total_duration_us = int(shot_df['duration'].sum() * 1000000)
    
    # æ„å»ºè‰ç¨¿ç»“æ„
    generator.add_audio_track(audio_name, total_duration_us)
    generator.add_media_track(shot_df, total_duration_us)
    
    draft_content = generator.generate_json()
    draft_meta = {"id": draft_content["id"], "name": "Mystery_Project", "last_modified": int(time.time()*1000)}

    with zipfile.ZipFile(buf, "w") as zf:
        zf.writestr("draft_content.json", json.dumps(draft_content, indent=4))
        zf.writestr("draft_meta_info.json", json.dumps(draft_meta, indent=4))
        zf.writestr(f"media/{audio_name}", audio_bytes)
        for i, u in imgs.items():
            try: zf.writestr(f"media/{i+1:03d}.jpg", requests.get(u).content)
            except: pass
    return buf

# ==========================================
# 5. ç•Œé¢ UI
# ==========================================
if 'char_df' not in st.session_state: st.session_state.char_df = None
if 'shot_df' not in st.session_state: st.session_state.shot_df = None
if 'gen_imgs' not in st.session_state: st.session_state.gen_imgs = {}
if 'audio_data' not in st.session_state: st.session_state.audio_data = None
if 'segments' not in st.session_state: st.session_state.segments = []

with st.sidebar:
    st.markdown("### ğŸ”‘ API Key"); api_key = st.text_input("SiliconFlow Key", type="password")
    st.markdown("### ğŸ•µï¸ åšä¸»å½¢è±¡"); fixed_host = st.text_area("Prompt", "(A 30-year-old Asian man, green cap, leather jacket:1.4)", height=80)
    st.markdown("### ğŸ› ï¸ è®¾ç½®"); model = st.selectbox("å¤§è„‘", ["Qwen/Qwen2.5-72B-Instruct", "deepseek-ai/DeepSeek-V3"])
    res_str, res_prompt = {"16:9":("1280x720","Cinematic 16:9"), "9:16":("720x1280","9:16 portrait")}[st.selectbox("ç”»å¹…", ["16:9", "9:16"])]
    style = st.text_area("é£æ ¼", "Film noir, suspense thriller.", height=60)

st.title("ğŸ“¦ MysteryNarrator V17 (å®Œç¾è‰ç¨¿ç‰ˆ)")
st.caption("é€»è¾‘ä¿®æ­£ï¼šå…ˆæ–‡æ¡ˆåˆ†æè§’è‰² -> åå½•éŸ³å¯¹é½æ—¶é—´ -> å¯¼å‡ºå‰ªæ˜ è‰ç¨¿")

# --- Step 1: æ–‡æ¡ˆä¸å½•éŸ³ ---
c1, c2 = st.columns(2)
with c1:
    script_input = st.text_area("1. ç²˜è´´æ–‡æ¡ˆ (ç”¨äºç²¾å‡†åˆ†æè§’è‰²)", height=150)
with c2:
    audio = st.file_uploader("2. ä¸Šä¼ å½•éŸ³ (ç”¨äºå¯¹é½æ—¶é—´)", type=['mp3','wav','m4a'])

if st.button("ğŸ” 3. åˆ†ææ–‡æ¡ˆ & å¬å†™å¯¹é½"):
    if not api_key: st.error("è¯·å¡« Key")
    elif not script_input or not audio: st.warning("è¯·åŒæ—¶æä¾›æ–‡æ¡ˆå’Œå½•éŸ³")
    else:
        st.session_state.audio_data = {"name": audio.name, "bytes": audio.getvalue()}
        
        # å¹¶è¡Œå¤„ç†ï¼šæ–‡æ¡ˆåˆ†æè§’è‰² + å½•éŸ³åˆ†ææ—¶é—´
        with st.spinner("åŒçº¿å¤„ç†ä¸­ï¼šåˆ†æè§’è‰² + è¯­éŸ³å¯¹é½..."):
            # 1. å¬å†™ (è·å–æ—¶é—´è½´)
            asr = transcribe_audio(audio, api_key)
            if asr:
                # å¼ºåˆ¶åˆ‡åˆ†é•¿å¥ (ä¿è¯å­—å¹•çŸ­)
                st.session_state.segments = split_long_segments(asr.get('segments', []), max_len=18)
                
                # 2. è§’è‰²æå– (ç”¨å·¦è¾¹çš„çº¯æ–‡æ¡ˆï¼Œæ›´å‡†)
                df = extract_characters_silicon(script_input, model, api_key)
                if df is not None:
                    host = pd.DataFrame([{"name":"åšä¸»(æˆ‘)", "prompt":fixed_host}])
                    st.session_state.char_df = pd.concat([host, df], ignore_index=True)
                    st.success(f"åˆ†æå®Œæˆï¼å…± {len(st.session_state.segments)} ä¸ªåˆ†é•œã€‚")

# --- Step 2: ç¡®è®¤ ---
if st.session_state.char_df is not None:
    st.markdown("---")
    st.session_state.char_df = st.data_editor(st.session_state.char_df, num_rows="dynamic", key="c_ed")
    
    if st.button("ğŸ¬ 4. ç”Ÿæˆåˆ†é•œè¡¨"):
        with st.spinner("å¯¼æ¼”è®¾è®¡ä¸­..."):
            c_list = st.session_state.char_df['name'].tolist()
            # ç”¨å¬å†™å‡ºæ¥çš„ segments (å¸¦æ—¶é—´) + è§’è‰²è¡¨ + é£æ ¼
            df = analyze_segments(st.session_state.segments, c_list, style, res_prompt, model, api_key)
            if df is not None:
                st.session_state.shot_df = inject_character_prompts(df, st.session_state.char_df)
                st.success("åˆ†é•œå·²ç”Ÿæˆ")

# --- Step 3: ç»˜å›¾ä¸å¯¼å‡º ---
if st.session_state.shot_df is not None:
    st.session_state.shot_df = st.data_editor(st.session_state.shot_df, num_rows="dynamic", key="s_ed")
    
    col_a, col_b = st.columns(2)
    if col_a.button("ğŸš€ 5. å¼€å§‹ç»˜å›¾"):
        bar = st.progress(0); tot = len(st.session_state.shot_df); prev = st.columns(4)
        for i, r in st.session_state.shot_df.iterrows():
            url = generate_image(r['final_prompt'], res_str, api_key)
            if "Error" not in url:
                st.session_state.gen_imgs[i] = url
                with prev[i%4]: st.image(url, caption=f"{i+1}", use_column_width=True)
            bar.progress((i+1)/tot)
            if i < tot-1: time.sleep(32)
        st.success("ç»˜å›¾å®Œæˆ!")

    if col_b.button("ğŸ“¦ 6. ä¸‹è½½è‰ç¨¿åŒ… (JianyingDraft.zip)"):
        if st.session_state.gen_imgs:
            zip_buf = create_draft_zip(
                st.session_state.shot_df, 
                st.session_state.gen_imgs, 
                st.session_state.audio_data["bytes"],
                st.session_state.audio_data["name"]
            )
            st.download_button("â¬‡ï¸ ä¸‹è½½å·¥ç¨‹åŒ…", zip_buf.getvalue(), "Jianying_Draft.zip", "application/zip")
        else: st.warning("è¯·å…ˆç»˜å›¾")
