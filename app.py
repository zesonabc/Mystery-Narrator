import streamlit as st
import requests
import pandas as pd
import json
import re
import time
import zipfile
import io
import uuid
import os

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="MysteryNarrator V24 (FLUXç‰ˆ)", page_icon="ğŸŒ", layout="wide")
st.markdown("""
<style>
    .stApp { background-color: #121212; color: #e0e0e0; }
    .stButton > button { background-color: #7C4DFF; color: white; border: none; padding: 12px; font-weight: bold; border-radius: 6px; }
    .stSuccess { background-color: #2e7d32; color: white; }
    .stWarning { background-color: #ff6f00; color: white; }
    /* å›¾ç‰‡ hover æ”¾å¤§æ•ˆæœ */
    img:hover { transform: scale(1.02); transition: 0.3s; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. å‰ªæ˜ è‰ç¨¿ç”Ÿæˆå™¨ (ä¿æŒä¸å˜)
# ==========================================
class JianyingDraftGenerator:
    def __init__(self):
        self.materials = {"videos": [], "audios": [], "texts": [], "canvas_animations": []}
        self.tracks = []
        self.width = 1920
        self.height = 1080
        self.us_base = 1000000 

    def _get_id(self): return str(uuid.uuid4()).upper()

    def add_media_track(self, shot_df, audio_duration_us):
        # è§†é¢‘è½¨é“
        video_segments = []
        current_offset = 0
        for i, row in shot_df.iterrows():
            material_id = self._get_id()
            duration_us = int(row['duration'] * self.us_base)
            self.materials["videos"].append({
                "id": material_id, "type": "photo", "path": f"D:/Mystery_Project/media/{i+1:03d}.jpg",
                "duration": 10800000000, "width": self.width, "height": self.height, "name": f"{i+1:03d}.jpg"
            })
            video_segments.append({
                "id": self._get_id(), "material_id": material_id,
                "target_timerange": {"duration": duration_us, "start": current_offset},
                "source_timerange": {"duration": duration_us, "start": 0}
            })
            current_offset += duration_us
        self.tracks.append({"id": self._get_id(), "type": "video", "segments": video_segments})

        # å­—å¹•è½¨é“
        text_segments = []
        current_offset = 0
        for i, row in shot_df.iterrows():
            duration_us = int(row['duration'] * self.us_base)
            text_id = self._get_id()
            # ç®€å•çš„å­—å¹•æ ·å¼
            content = {"text": str(row['script']), "styles": [{"fill": {"color": [1.0, 1.0, 1.0]}}], "strokes": [{"color": [0.0, 0.0, 0.0], "width": 0.05}]}
            self.materials["texts"].append({
                "id": text_id, "type": "text", "content": json.dumps(content), "font_size": 12.0
            })
            text_segments.append({
                "id": self._get_id(), "material_id": text_id,
                "target_timerange": {"duration": duration_us, "start": current_offset},
                "source_timerange": {"duration": duration_us, "start": 0}
            })
            current_offset += duration_us
        self.tracks.append({"id": self._get_id(), "type": "text", "segments": text_segments})

    def add_audio_track(self, audio_filename, duration_us):
        audio_id = self._get_id()
        self.materials["audios"].append({
            "id": audio_id, "path": f"D:/Mystery_Project/media/{audio_filename}",
            "duration": duration_us, "type": "extract_music", "name": audio_filename
        })
        self.tracks.append({"id": self._get_id(), "type": "audio", "segments": [{
            "id": self._get_id(), "material_id": audio_id,
            "target_timerange": {"duration": duration_us, "start": 0},
            "source_timerange": {"duration": duration_us, "start": 0}
        }]})

    def generate_json(self):
        return {"id": self._get_id(), "materials": self.materials, "tracks": self.tracks, "version": 3, "config": {"width": self.width, "height": self.height}}

# ==========================================
# 3. æ ¸å¿ƒ API (SiliconFlow æ·±åº¦é€‚é…)
# ==========================================
def get_headers(api_key): return {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}

# æ¸…æ´— DeepSeek çš„æ€è€ƒè¿‡ç¨‹ <think>...</think>
def clean_json_text(text): 
    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
    text = re.sub(r'```json|```', '', text)
    return text.strip()

# 1. è¯­éŸ³è½¬æ–‡å­— (ä¿æŒä¸å˜)
def transcribe_audio(audio_file, api_key):
    url = "https://api.siliconflow.cn/v1/audio/transcriptions"
    audio_file.seek(0)
    files = {'file': (audio_file.name, audio_file.getvalue(), audio_file.type), 'model': (None, 'FunAudioLLM/SenseVoiceSmall'), 'response_format': (None, 'verbose_json')}
    try: 
        res = requests.post(url, headers={"Authorization": f"Bearer {api_key}"}, files=files, timeout=60)
        return res.json()
    except: return None

# 2. ã€é‡ç‚¹ä¿®å¤ã€‘äººç‰©æå–ï¼šå¢å¼º Promptï¼Œä¸å†åªçœ‹åšä¸»
def extract_characters_silicon(script, model, key):
    url = "https://api.siliconflow.cn/v1/chat/completions"
    
    # å¼ºåŠ› Promptï¼šå¼ºåˆ¶è¦æ±‚å¯»æ‰¾å—å®³è€…ã€å«Œç–‘äººç­‰
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªæ‚¬ç–‘å‰§æœ¬åˆ†æå¸ˆã€‚ä»»åŠ¡ï¼šæå–å‰§æœ¬ä¸­é™¤äº†â€œæˆ‘/åšä¸»â€ä»¥å¤–çš„æ‰€æœ‰å…³é”®è§’è‰²ã€‚
    
    è§„åˆ™ï¼š
    1. é‡ç‚¹å¯»æ‰¾ï¼šå—å®³è€…ã€å«Œç–‘äººã€ç›®å‡»è€…ã€ç¥ç§˜äººï¼ˆå¦‚â€œçº¢è¡£å¥³å­â€ã€â€œè€å¤´â€ã€â€œæ€ªç‰©â€ï¼‰ã€‚
    2. å¦‚æœæ²¡æœ‰åå­—ï¼Œå°±ç”¨å¤–è²Œä»£å·ã€‚
    3. ä¸ºæ¯ä¸ªè§’è‰²å†™ä¸€æ®µç®€çŸ­çš„è‹±æ–‡å¤–è²Œæè¿° (Prompt)ã€‚
    
    è¾“å‡ºæ ¼å¼(JSON List): [{'name':'ç‹æŸ','prompt':'A middle-aged man, fat, scared face'}, {'name':'çº¢è¡£å¥³','prompt':'A woman in red dress, long hair, creepy smile'}]
    """
    
    try:
        payload = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": script}
            ],
            "response_format": {"type": "json_object"}
        }
        res = requests.post(url, json=payload, headers=get_headers(key), timeout=45)
        
        content = clean_json_text(res.json()['choices'][0]['message']['content'])
        
        # å°è¯•è§£æ
        try:
            data = json.loads(content)
            # æœ‰æ—¶å€™æ¨¡å‹ä¼šåŒ…è£¹åœ¨ 'characters' é”®é‡Œ
            if isinstance(data, dict) and 'characters' in data:
                data = data['characters']
            elif isinstance(data, dict) and 'list' in data:
                data = data['list']
            
            df = pd.DataFrame(data)
            
            # è¿‡æ»¤æ‰åšä¸»è‡ªå·± (åŒé‡ä¿é™©)
            if not df.empty: 
                df = df[~df['name'].str.contains('åšä¸»|æˆ‘|Host|Narrator', case=False, na=False)]
            return df
        except:
            return pd.DataFrame(columns=['name', 'prompt'])
            
    except Exception as e:
        print(f"äººç‰©åˆ†æå‡ºé”™: {e}")
        return pd.DataFrame(columns=['name', 'prompt'])

# 3. åˆ†é•œåˆ†æ (ä¿æŒç¨³å¥)
def analyze_segments_robust(segments, script_text, char_names, style, res_p, model, key):
    final_segments = []
    if segments:
        final_segments = segments
    else:
        # æ‰‹åŠ¨åˆ‡åˆ†å…œåº•
        chunks = re.split(r'([ã€‚ï¼Ÿï¼ï¼›\n])', script_text)
        current = ""
        for chunk in chunks:
            if len(current) + len(chunk) < 18 and not re.match(r'[ã€‚ï¼Ÿï¼\n]', chunk): current += chunk
            else: 
                if current: final_segments.append({"text": current, "duration": 5.0})
                current = chunk
        if current: final_segments.append({"text": current, "duration": 5.0})

    try:
        # æ„é€ è¾“å…¥
        input_data = json.dumps([{"id":i,"text":s.get('text', '')} for i,s in enumerate(final_segments)], ensure_ascii=False)
        char_list = ", ".join(char_names) if char_names else "æ— ç‰¹å®šè§’è‰²"
        
        sys_prompt = f"""
        ä½ æ˜¯æ‚¬ç–‘ç”µå½±å¯¼æ¼”ã€‚
        ã€å·²çŸ¥è§’è‰²ã€‘: {char_list}
        ã€æ•´ä½“é£æ ¼ã€‘: {style}
        ã€ç”»é¢æ„å›¾ã€‘: {res_p}
        
        ä»»åŠ¡: ä¸ºæ¯ä¸€å¥å­—å¹•è®¾è®¡ç”»é¢ Promptã€‚
        è§„åˆ™:
        1. é‡åˆ°å…·ä½“è§’è‰²åå­—æ—¶ï¼ŒPrompt é‡Œå¿…é¡»åŒ…å«è¯¥åå­—çš„è‹±æ–‡æè¿°ï¼ˆä¾‹å¦‚ 'A woman in red'ï¼‰ã€‚
        2. å¦‚æœæ˜¯ç©ºé•œå¤´/ç¯å¢ƒæå†™ï¼Œä¸è¦åŠ äººã€‚
        3. è¾“å‡º JSON: {{"segments": [{{"index": 0, "type": "SCENE/HOST", "final_prompt": "..."}}]}}
        """
        
        payload = {
            "model": model,
            "messages": [
                {"role": "system", "content": sys_prompt},
                {"role": "user", "content": input_data}
            ],
            "response_format": {"type": "json_object"}
        }
        
        res = requests.post("https://api.siliconflow.cn/v1/chat/completions", json=payload, headers=get_headers(key), timeout=90)
        result_content = clean_json_text(res.json()['choices'][0]['message']['content'])
        result_json = json.loads(result_content)
        
        result_list = result_json.get('segments', [])
        
        merged = []
        for i, seg in enumerate(final_segments):
            # åŒ¹é…ç»“æœ
            vis = next((item for item in result_list if item.get('index') == i), None)
            
            # è®¡ç®—æ—¶é•¿
            dur = seg.get('duration')
            if dur is None and 'end' in seg and 'start' in seg: 
                dur = seg['end'] - seg['start']
            if dur is None: dur = 5.0
            
            merged.append({
                "duration": dur,
                "script": seg.get('text'),
                "type": vis['type'] if vis else "SCENE",
                "final_prompt": vis['final_prompt'] if vis else f"Suspense scene, {style}"
            })
        return pd.DataFrame(merged)

    except Exception as e:
        print(f"åˆ†é•œåˆ†æå‡ºé”™: {e}")
        # å‡ºé”™å…œåº•
        fallback = []
        for seg in final_segments:
            dur = seg.get('duration', 5.0)
            fallback.append({"duration": dur, "script": seg.get('text'), "type": "SCENE", "final_prompt": f"Suspense shot, {style}"})
        return pd.DataFrame(fallback)

def inject_character_prompts(shot_df, char_df):
    if shot_df is None or shot_df.empty or 'final_prompt' not in shot_df.columns: return shot_df
    # ç®€å•çš„æ–‡æœ¬æ›¿æ¢å¢å¼º
    return shot_df

# 4. ã€é‡ç‚¹å‡çº§ã€‘ç»˜å›¾å¼•æ“ï¼šFLUX.1-schnell
# è¿™æ˜¯ SiliconFlow ä¸Šç›®å‰æ€§ä»·æ¯”æœ€é«˜ã€ç”»è´¨æœ€å¥½çš„æ¨¡å‹
def generate_image(prompt, size, key):
    try:
        # è¿™é‡Œçš„ size éœ€è¦è½¬æ¢ä¸€ä¸‹æ ¼å¼ï¼ŒFLUX é€šå¸¸æ¥å— "1024x1024" ç­‰
        # ä¸ºäº†å®‰å…¨ï¼Œæˆ‘ä»¬å›ºå®šç”¨ FLUX çš„æ ‡å‡†å°ºå¯¸
        width, height = 1280, 720 # 16:9
        if "9:16" in size: width, height = 720, 1280
        
        payload = {
            "model": "black-forest-labs/FLUX.1-schnell", # ğŸ‘ˆ æ——èˆ°æ¨¡å‹
            "prompt": prompt,
            "image_size": f"{width}x{height}",
            "batch_size": 1,
            "num_inference_steps": 4, # Schnell 4æ­¥å°±èƒ½å‡ºå›¾ï¼Œæå¿«
            "guidance_scale": 3.5
        }
        
        res = requests.post(
            "https://api.siliconflow.cn/v1/images/generations", 
            json=payload, 
            headers=get_headers(key), 
            timeout=50
        )
        
        if res.status_code == 200:
            return res.json()['images'][0]['url']
        else:
            print(f"ç»˜å›¾æŠ¥é”™: {res.text}")
            return "Error"
    except Exception as e: 
        print(f"è¯·æ±‚å¼‚å¸¸: {e}")
        return "Error"

def create_draft_zip(shot_df, imgs, audio_bytes, audio_name):
    buf = io.BytesIO()
    generator = JianyingDraftGenerator()
    total_duration_us = int(shot_df['duration'].sum() * 1000000)
    generator.add_audio_track(audio_name, total_duration_us)
    generator.add_media_track(shot_df, total_duration_us)
    
    draft_content = generator.generate_json()
    draft_meta = {"id": draft_content["id"], "name": "Mystery_Project", "last_modified": int(time.time()*1000)}

    with zipfile.ZipFile(buf, "w") as zf:
        zf.writestr("draft_content.json", json.dumps(draft_content, indent=4))
        zf.writestr("draft_meta_info.json", json.dumps(draft_meta, indent=4))
        zf.writestr(f"media/{audio_name}", audio_bytes)
        for i, u in imgs.items():
            try: zf.writestr(f"media/{i+1:03d}.jpg", requests.get(u).content)
            except: pass
    return buf

# ==========================================
# 5. ä¸»ç•Œé¢é€»è¾‘
# ==========================================
if 'char_df' not in st.session_state: st.session_state.char_df = None
if 'shot_df' not in st.session_state: st.session_state.shot_df = None
if 'gen_imgs' not in st.session_state: st.session_state.gen_imgs = {}
if 'audio_data' not in st.session_state: st.session_state.audio_data = None
if 'segments' not in st.session_state: st.session_state.segments = []

with st.sidebar:
    st.markdown("### ğŸ”‘ é…ç½®ä¸­å¿ƒ")
    api_key = st.text_input("SiliconFlow API Key", type="password")
    
    st.markdown("### ğŸ•µï¸ å›ºå®šè§’è‰²")
    fixed_host = st.text_area("åšä¸» Prompt", "(A 30-year-old Asian man, green cap, leather jacket:1.4), looking at camera", height=80)
    
    st.markdown("### ğŸ§  æ¨¡å‹é€‰æ‹©")
    # ä¿®æ­£æ¨¡å‹åç§°ï¼ŒDeepSeek V3 æ˜¯ç›®å‰æœ€ç¨³çš„
    model = st.selectbox("å¤§è„‘æ¨¡å‹", ["deepseek-ai/DeepSeek-V3", "Qwen/Qwen2.5-72B-Instruct"])
    
    # FLUX å°ºå¯¸é€‰æ‹©
    aspect = st.selectbox("ç”»å¹…", ["16:9 (æ¨ªå±)", "9:16 (ç«–å±)"])
    res_str = "16:9" if "16:9" in aspect else "9:16"
    res_prompt = "Cinematic 16:9" if "16:9" in aspect else "Portrait 9:16"
    
    style = st.text_area("æ•´ä½“é£æ ¼", "Film noir, suspense thriller, dramatic lighting, 80s film grain, high details.", height=60)
    
    st.info("ğŸ¨ ç»˜å›¾å·²å‡çº§ä¸º: FLUX.1-schnell (æ›´å¿«æ›´å¼º)")

st.title("ğŸš€ MysteryNarrator V24 (SiliconFlow FLUXç‰ˆ)")
st.caption("é€»è¾‘å¤§è„‘: DeepSeek V3 | è§†è§‰å¼•æ“: FLUX.1-schnell")

c1, c2 = st.columns(2)
with c1: script_input = st.text_area("1. ç²˜è´´æ–‡æ¡ˆ (æ— éœ€æ ‡ç‚¹å®Œç¾)", height=150)
with c2: audio = st.file_uploader("2. ä¸Šä¼ å½•éŸ³ (MP3/WAV)", type=['mp3','wav','m4a'])

# --- æ­¥éª¤ 3: åˆ†æ ---
if st.button("ğŸ” 3. æ™ºèƒ½åˆ†æ"):
    if not api_key: st.error("è¯·å¡«å…¥ SiliconFlow Key")
    elif not script_input or not audio: st.error("è¯·æä¾›æ–‡æ¡ˆå’Œå½•éŸ³")
    else:
        st.session_state.audio_data = {"name": audio.name, "bytes": audio.getvalue()}
        
        with st.spinner("ğŸ§ æ­£åœ¨å¬å†™å½•éŸ³æ—¶é—´è½´..."):
            asr = transcribe_audio(audio, api_key)
            if asr and 'segments' in asr and len(asr['segments']) > 0:
                st.session_state.segments = asr['segments']
                st.success(f"âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸï¼Œå…± {len(asr['segments'])} å¥è¯ã€‚")
            else:
                st.session_state.segments = []
                st.warning("âš ï¸ è¯­éŸ³è¯†åˆ«æœªè¿”å›æ—¶é—´è½´ï¼Œå°†ä½¿ç”¨é»˜è®¤æ—¶é•¿ã€‚")

        with st.spinner("ğŸ•µï¸ æ­£åœ¨æŒ–æ˜å‰§æœ¬ä¸­çš„å—å®³è€…å’Œé…è§’..."):
            df = extract_characters_silicon(script_input, model, api_key)
            if df is None: df = pd.DataFrame(columns=['name', 'prompt'])
            
            # æŠŠåšä¸»åŠ åˆ°ç¬¬ä¸€è¡Œ
            host = pd.DataFrame([{"name":"åšä¸»(æˆ‘)", "prompt":fixed_host}])
            st.session_state.char_df = pd.concat([host, df], ignore_index=True)
            st.success("âœ… è§’è‰²æå–å®Œæˆï¼")

# --- è§’è‰²ç¼–è¾‘åŒº ---
if st.session_state.char_df is not None:
    st.markdown("##### ğŸ­ è§’è‰²åˆ—è¡¨ (å¯ä¿®æ”¹)")
    st.session_state.char_df = st.data_editor(st.session_state.char_df, num_rows="dynamic", key="c_ed", use_container_width=True)
    
    if st.button("ğŸ¬ 4. ç”Ÿæˆåˆ†é•œè¡¨"):
        with st.spinner(f"ğŸ§  {model} æ­£åœ¨æ‹…ä»»å¯¼æ¼”ï¼Œè®¾è®¡åˆ†é•œ..."):
            c_list = st.session_state.char_df['name'].tolist()
            df = analyze_segments_robust(st.session_state.segments, script_input, c_list, style, res_prompt, model, api_key)
            # ç®€å•çš„ Prompt æ³¨å…¥
            st.session_state.shot_df = inject_character_prompts(df, st.session_state.char_df)
            st.success("âœ… åˆ†é•œè®¾è®¡å®Œæ¯•ï¼")

# --- åˆ†é•œç¼–è¾‘ä¸ç»˜å›¾ ---
if st.session_state.shot_df is not None and not st.session_state.shot_df.empty:
    st.markdown("##### ğŸ“‹ åˆ†é•œè¡¨ (å¯å¾®è°ƒ Prompt)")
    st.session_state.shot_df = st.data_editor(
        st.session_state.shot_df, 
        num_rows="dynamic", 
        key="s_ed", 
        use_container_width=True,
        column_config={
            "final_prompt": st.column_config.TextColumn("ç»˜å›¾æŒ‡ä»¤", width="large"),
            "type": st.column_config.SelectboxColumn("ç±»å‹", options=["HOST", "SCENE"], width="small"),
            "duration": st.column_config.NumberColumn("æ—¶é•¿(ç§’)", format="%.1f")
        }
    )
    
    col1, col2 = st.columns(2)
    if col1.button("ğŸ¨ 5. FLUX æé€Ÿç»˜å›¾"):
        if not api_key: st.error("No Key")
        else:
            bar = st.progress(0)
            tot = len(st.session_state.shot_df)
            
            # åˆ›å»ºç½‘æ ¼æ˜¾ç¤ºå›¾ç‰‡
            img_container = st.container()
            cols = img_container.columns(4)
            
            for i, r in st.session_state.shot_df.iterrows():
                # è°ƒç”¨ FLUX
                url = generate_image(r['final_prompt'], res_str, api_key)
                
                if "Error" not in url:
                    st.session_state.gen_imgs[i] = url
                    # å®æ—¶æ˜¾ç¤º
                    with cols[i % 4]:
                        st.image(url, caption=f"#{i+1} {r['type']}", use_column_width=True)
                else:
                    st.warning(f"ç¬¬ {i+1} å¼ ç”Ÿæˆå¤±è´¥")

                bar.progress((i+1)/tot)
                # FLUX Schnell éå¸¸å¿«ï¼Œä¸” SiliconFlow é™åˆ¶è¾ƒå®½æ¾ï¼Œé—´éš” 2 ç§’å³å¯ï¼Œä¸ç”¨ 35 ç§’
                if i < tot-1: time.sleep(2) 
            
            st.success("ğŸ‰ å…¨éƒ¨ç»˜å›¾å®Œæˆï¼")

    if col2.button("ğŸ“¦ 6. ä¸‹è½½å‰ªæ˜ è‰ç¨¿åŒ…"):
        if st.session_state.gen_imgs:
            zip_buf = create_draft_zip(st.session_state.shot_df, st.session_state.gen_imgs, st.session_state.audio_data["bytes"], st.session_state.audio_data["name"])
            st.download_button("â¬‡ï¸ ç‚¹å‡»ä¸‹è½½ ZIP", zip_buf.getvalue(), "Jianying_Mystery_Draft.zip", "application/zip", type="primary")
        else: 
            st.warning("âš ï¸ è¯·å…ˆç‚¹å‡»å·¦ä¾§æŒ‰é’®ç”Ÿæˆå›¾ç‰‡")
